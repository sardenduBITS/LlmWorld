# llmIntro
Explore llm with ollama

### Notes
1. Install ollama https://ollama.com/download
2. Download any inference model like llama3.2  https://ollama.com/library/llama3.2 with this command:  `ollama pull llama3.2`
3. Download any inference model like nomic-embed-text https://ollama.com/library/nomic-embed-text with this command: `ollama pull nomic-embed-text`
4. Make sure ollama server is running on your local machine before starting the app.
5. Install dependencies: `pip install -r requirement.txt`
6. Keep one csv file inside data folder
7. Start the app: `streamlit run app.py`
8. output screenshot 
